#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ–‡ä»¶ç®¡ç†å™¨ - å¤„ç†AIæ¨¡å‹çš„ä¸‹è½½ã€æ£€æŸ¥å’ŒåŠ è½½
"""

import os
import sys
import json
import shutil
import requests
import zipfile
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)

class ModelManager:
    """æ¨¡å‹æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = None):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰ç›®å½•
        """
        if base_dir is None:
            base_dir = os.path.dirname(os.path.abspath(__file__))
        
        self.base_dir = Path(base_dir)
        self.models_dir = self.base_dir / 'data' / 'models'
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.model_config = {
            'sentence_transformer': {
                'name': 'all-MiniLM-L6-v2',
                'url': 'https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main',
                'mirror_url': 'https://fastgh.discoverlife.top/https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main',
                'files': [
                    'config.json',
                    'pytorch_model.bin',
                    'sentence_bert_config.json',
                    'special_tokens_map.json',
                    'tokenizer.json',
                    'tokenizer_config.json',
                    'vocab.txt'
                ],
                'size_mb': 90  # é¢„ä¼°å¤§å°
            },
            'faiss_index': {
                'name': 'faiss_index',
                'files': ['faiss_index.bin', 'metadata.json'],
                'size_mb': 10  # é¢„ä¼°å¤§å°
            }
        }
    
    def _get_proxy_config(self) -> Optional[Dict[str, str]]:
        """
        è·å–ä»£ç†é…ç½®
        
        Returns:
            Dict[str, str]: ä»£ç†é…ç½®å­—å…¸ï¼Œå¦‚æœä¸éœ€è¦ä»£ç†åˆ™è¿”å›None
        """
        try:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
            http_proxy = os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')
            https_proxy = os.environ.get('https_proxy') or os.environ.get('HTTPS_PROXY')
            
            if http_proxy or https_proxy:
                proxies = {}
                if http_proxy:
                    proxies['http'] = http_proxy
                if https_proxy:
                    proxies['https'] = https_proxy
                logger.info(f"æ£€æµ‹åˆ°ä»£ç†é…ç½®: {proxies}")
                return proxies
            else:
                # é»˜è®¤ä½¿ç”¨127.0.0.1:7890ä»£ç†
                proxies = {
                    'http': 'http://127.0.0.1:7890',
                    'https': 'http://127.0.0.1:7890'
                }
                logger.info(f"ä½¿ç”¨é»˜è®¤ä»£ç†é…ç½®: {proxies}")
                return proxies
                
        except Exception as e:
            logger.warning(f"ä»£ç†é…ç½®è·å–å¤±è´¥: {e}")
            return None
    
    def check_ai_dependencies(self) -> bool:
        """
        æ£€æŸ¥AIä¾èµ–æ˜¯å¦å·²å®‰è£…ï¼ˆå®½æ¾æ£€æŸ¥ï¼‰
        
        Returns:
            bool: Trueå¦‚æœAIä¾èµ–å¯ç”¨ï¼ŒFalseå¦åˆ™
        """
        try:
            # åªæ£€æŸ¥åŸºç¡€åŒ…ï¼Œä¸å¼ºåˆ¶è¦æ±‚æ‰€æœ‰åŒ…éƒ½å¯ç”¨
            import torch
            logger.info("âœ… torch å¯ç”¨")
            return True
        except ImportError as e:
            logger.warning(f"âš ï¸ torch ä¸å¯ç”¨: {e}")
            # å³ä½¿torchä¸å¯ç”¨ï¼Œä¹Ÿå°è¯•ç»§ç»­ï¼ˆå¯èƒ½ä½¿ç”¨CPUç‰ˆæœ¬ï¼‰
            try:
                import faiss
                logger.info("âœ… faiss å¯ç”¨")
                return True
            except ImportError as e2:
                logger.warning(f"âš ï¸ faiss ä¸å¯ç”¨: {e2}")
                # æœ€åå°è¯•sentence_transformers
                try:
                    import sentence_transformers
                    logger.info("âœ… sentence_transformers å¯ç”¨")
                    return True
                except ImportError as e3:
                    logger.warning(f"âš ï¸ sentence_transformers ä¸å¯ç”¨: {e3}")
                    logger.info("ğŸ’¡ å°†ä½¿ç”¨åŸºç¡€ç›¸ä¼¼åº¦ç®—æ³•ä½œä¸ºåå¤‡")
                    return False
    
    def check_model_files(self) -> Dict[str, bool]:
        """
        æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Returns:
            Dict[str, bool]: å„æ¨¡å‹æ–‡ä»¶çš„æ£€æŸ¥ç»“æœ
        """
        results = {}
        
        # æ£€æŸ¥sentence transformeræ¨¡å‹
        st_model_dir = self.models_dir / 'sentence-transformers' / 'all-MiniLM-L6-v2'
        st_files_exist = all(
            (st_model_dir / file).exists() 
            for file in self.model_config['sentence_transformer']['files']
        )
        results['sentence_transformer'] = st_files_exist
        
        # æ£€æŸ¥faissç´¢å¼•
        faiss_files_exist = all(
            (self.models_dir / 'similarity_index' / file).exists()
            for file in self.model_config['faiss_index']['files']
        )
        results['faiss_index'] = faiss_files_exist
        
        return results
    
    def get_model_status(self) -> Dict[str, any]:
        """
        è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯
        
        Returns:
            Dict: åŒ…å«æ¨¡å‹çŠ¶æ€ã€ä¾èµ–çŠ¶æ€ç­‰ä¿¡æ¯
        """
        ai_deps_available = self.check_ai_dependencies()
        model_files_status = self.check_model_files()
        
        return {
            'ai_dependencies_available': ai_deps_available,
            'model_files_status': model_files_status,
            'all_ready': ai_deps_available and all(model_files_status.values()),
            'models_dir': str(self.models_dir)
        }
    
    def download_model_file(self, model_name: str, file_name: str, 
                          progress_callback=None) -> bool:
        """
        ä¸‹è½½å•ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒå¤‡ç”¨ä¸‹è½½åœ°å€å’Œä»£ç†
        
        Args:
            model_name: æ¨¡å‹åç§°
            file_name: æ–‡ä»¶å
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            if model_name == 'sentence_transformer':
                base_url = self.model_config['sentence_transformer']['url']
                mirror_url = self.model_config['sentence_transformer']['mirror_url']
                target_dir = self.models_dir / 'sentence-transformers' / 'all-MiniLM-L6-v2'
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_name}")
                return False
            
            target_dir.mkdir(parents=True, exist_ok=True)
            target_file = target_dir / file_name
            
            # å°è¯•å¤šä¸ªä¸‹è½½åœ°å€
            urls_to_try = [
                f"{base_url}/{file_name}",
                f"{mirror_url}/{file_name}"
            ]
            
            # é…ç½®ä»£ç†
            proxies = self._get_proxy_config()
            
            for i, url in enumerate(urls_to_try):
                try:
                    logger.info(f"å°è¯•ä¸‹è½½æ–‡ä»¶: {file_name} (æº {i+1}/{len(urls_to_try)})")
                    logger.info(f"ä¸‹è½½åœ°å€: {url}")
                    if proxies:
                        logger.info(f"ä½¿ç”¨ä»£ç†: {proxies}")
                    
                    response = requests.get(url, stream=True, timeout=30, proxies=proxies)
                    response.raise_for_status()
                    
                    total_size = int(response.headers.get('content-length', 0))
                    downloaded_size = 0
                    
                    with open(target_file, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                                
                                if progress_callback and total_size > 0:
                                    progress = (downloaded_size / total_size) * 100
                                    progress_callback(file_name, progress)
                    
                    logger.info(f"æ–‡ä»¶ä¸‹è½½å®Œæˆ: {file_name}")
                    return True
                    
                except Exception as e:
                    logger.warning(f"ä¸‹è½½å¤±è´¥ (æº {i+1}): {e}")
                    if i < len(urls_to_try) - 1:
                        logger.info(f"å°è¯•ä¸‹ä¸€ä¸ªä¸‹è½½æº...")
                        continue
                    else:
                        raise e
            
            return False
            
        except Exception as e:
            logger.error(f"æ‰€æœ‰ä¸‹è½½æºéƒ½å¤±è´¥ {file_name}: {e}")
            return False
    
    def download_sentence_transformer_model(self, progress_callback=None) -> bool:
        """
        ä¸‹è½½sentence transformeræ¨¡å‹
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶(file_name, progress)å‚æ•°
            
        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹ä¸‹è½½sentence transformeræ¨¡å‹...")
        
        success_count = 0
        total_files = len(self.model_config['sentence_transformer']['files'])
        
        for i, file_name in enumerate(self.model_config['sentence_transformer']['files']):
            if progress_callback:
                progress_callback(f"ä¸‹è½½ {file_name}", (i / total_files) * 100)
            
            if self.download_model_file('sentence_transformer', file_name, progress_callback):
                success_count += 1
        
        success = success_count == total_files
        if success:
            logger.info("sentence transformeræ¨¡å‹ä¸‹è½½å®Œæˆ")
        else:
            logger.error(f"æ¨¡å‹ä¸‹è½½ä¸å®Œæ•´: {success_count}/{total_files}")
        
        return success
    
    def create_faiss_index(self, progress_callback=None) -> bool:
        """
        åˆ›å»ºfaissç´¢å¼•æ–‡ä»¶ï¼ˆéœ€è¦AIä¾èµ–ï¼‰
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        if not self.check_ai_dependencies():
            logger.warning("AIä¾èµ–éƒ¨åˆ†ä¸å¯ç”¨ï¼Œå°†è·³è¿‡faissç´¢å¼•åˆ›å»º")
            logger.info("ğŸ’¡ ç³»ç»Ÿå°†ä½¿ç”¨åŸºç¡€ç›¸ä¼¼åº¦ç®—æ³•")
            return True  # ä¸è¿”å›Falseï¼Œå…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ
        
        try:
            from file_save.similarity_service import SimilarityService
            
            logger.info("åˆ›å»ºfaissç´¢å¼•...")
            if progress_callback:
                progress_callback("åˆ›å»ºç´¢å¼•", 0)
            
            # åˆ›å»ºç›¸ä¼¼åº¦æœåŠ¡å®ä¾‹
            similarity_service = SimilarityService()
            
            # é‡æ–°æ„å»ºç´¢å¼•
            similarity_service.rebuild_index()
            
            if progress_callback:
                progress_callback("åˆ›å»ºç´¢å¼•", 100)
            
            logger.info("faissç´¢å¼•åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºfaissç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def install_ai_dependencies(self, progress_callback=None) -> bool:
        """
        å®‰è£…AIä¾èµ–åŒ…
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            bool: å®‰è£…æ˜¯å¦æˆåŠŸ
        """
        try:
            import subprocess
            import sys
            
            logger.info("å¼€å§‹å®‰è£…AIä¾èµ–...")
            
            packages = [
                'sentence-transformers==2.7.0',
                'faiss-cpu==1.12.0',
                'torch>=2.1.0',
                'transformers==4.44.0'
            ]
            
            for i, package in enumerate(packages):
                if progress_callback:
                    progress_callback(f"å®‰è£… {package}", (i / len(packages)) * 100)
                
                logger.info(f"å®‰è£…åŒ…: {package}")
                result = subprocess.run([
                    sys.executable, '-m', 'pip', 'install', package
                ], capture_output=True, text=True)
                
                if result.returncode != 0:
                    logger.error(f"å®‰è£…å¤±è´¥ {package}: {result.stderr}")
                    return False
            
            logger.info("AIä¾èµ–å®‰è£…å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"å®‰è£…AIä¾èµ–å¤±è´¥: {e}")
            return False
    
    def setup_ai_environment(self, progress_callback=None) -> bool:
        """
        è®¾ç½®å®Œæ•´çš„AIç¯å¢ƒï¼ˆå®‰è£…ä¾èµ– + ä¸‹è½½æ¨¡å‹ï¼‰
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            bool: è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹è®¾ç½®AIç¯å¢ƒ...")
        
        # æ­¥éª¤1: å®‰è£…AIä¾èµ–
        if progress_callback:
            progress_callback("å®‰è£…AIä¾èµ–", 10)
        
        if not self.install_ai_dependencies(progress_callback):
            return False
        
        # æ­¥éª¤2: ä¸‹è½½sentence transformeræ¨¡å‹
        if progress_callback:
            progress_callback("ä¸‹è½½æ¨¡å‹æ–‡ä»¶", 50)
        
        if not self.download_sentence_transformer_model(progress_callback):
            return False
        
        # æ­¥éª¤3: åˆ›å»ºfaissç´¢å¼•
        if progress_callback:
            progress_callback("åˆ›å»ºç´¢å¼•", 90)
        
        if not self.create_faiss_index(progress_callback):
            return False
        
        if progress_callback:
            progress_callback("AIç¯å¢ƒè®¾ç½®å®Œæˆ", 100)
        
        logger.info("AIç¯å¢ƒè®¾ç½®å®Œæˆ")
        return True
    
    def cleanup_models(self) -> bool:
        """
        æ¸…ç†æ¨¡å‹æ–‡ä»¶
        
        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.models_dir.exists():
                shutil.rmtree(self.models_dir)
                self.models_dir.mkdir(parents=True, exist_ok=True)
                logger.info("æ¨¡å‹æ–‡ä»¶æ¸…ç†å®Œæˆ")
                return True
        except Exception as e:
            logger.error(f"æ¸…ç†æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
            return False


def get_model_manager() -> ModelManager:
    """è·å–æ¨¡å‹ç®¡ç†å™¨å®ä¾‹"""
    return ModelManager()


if __name__ == '__main__':
    # æµ‹è¯•æ¨¡å‹ç®¡ç†å™¨
    manager = ModelManager()
    
    print("=== æ¨¡å‹çŠ¶æ€æ£€æŸ¥ ===")
    status = manager.get_model_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))
    
    print("\n=== æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ ===")
    model_files = manager.check_model_files()
    print(json.dumps(model_files, indent=2, ensure_ascii=False))
