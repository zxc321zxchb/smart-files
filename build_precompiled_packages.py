#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é¢„ç¼–è¯‘åŒ…æ„å»ºè„šæœ¬
ç”¨äºæ„å»ºAIä¾èµ–åŒ…å’Œæ¨¡å‹åŒ…ï¼Œä¾›PyInstallerç¯å¢ƒä½¿ç”¨
"""

import os
import sys
import json
import zipfile
import hashlib
import shutil
import tempfile
from pathlib import Path
import subprocess
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PrecompiledPackageBuilder:
    """é¢„ç¼–è¯‘åŒ…æ„å»ºå™¨"""
    
    def __init__(self, base_dir: str = None):
        """
        åˆå§‹åŒ–æ„å»ºå™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•
        """
        if base_dir is None:
            base_dir = os.path.dirname(os.path.abspath(__file__))
        
        self.base_dir = Path(base_dir)
        self.build_dir = self.base_dir / 'build' / 'precompiled_packages'
        self.build_dir.mkdir(parents=True, exist_ok=True)
        
        # åŒ…é…ç½®
        self.package_configs = {
            'ai_dependencies': {
                'name': 'ai_dependencies',
                'version': '1.0.0',
                'description': 'AIä¾èµ–åŒ… - åŒ…å«sentence-transformers, torch, faissç­‰',
                'packages': [
                    'sentence-transformers==2.7.0',
                    'faiss-cpu==1.12.0',
                    'torch>=2.1.0',
                    'transformers==4.44.0',
                    'numpy>=1.26.0'
                ]
            },
            'ai_models': {
                'name': 'ai_models',
                'version': '1.0.0',
                'description': 'AIæ¨¡å‹åŒ… - åŒ…å«sentence transformeræ¨¡å‹å’Œfaissç´¢å¼•',
                'model_name': 'all-MiniLM-L6-v2'
            }
        }
    
    def create_virtual_environment(self, env_name: str) -> Path:
        """
        åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
        
        Args:
            env_name: ç¯å¢ƒåç§°
            
        Returns:
            Path: è™šæ‹Ÿç¯å¢ƒè·¯å¾„
        """
        env_path = self.build_dir / f"venv_{env_name}"
        
        if env_path.exists():
            logger.info(f"è™šæ‹Ÿç¯å¢ƒ {env_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
            return env_path
        
        logger.info(f"åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: {env_name}")
        result = subprocess.run([
            sys.executable, '-m', 'venv', str(env_path)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¤±è´¥: {result.stderr}")
        
        logger.info(f"è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ: {env_path}")
        return env_path
    
    def install_packages_to_venv(self, env_path: Path, packages: list) -> bool:
        """
        åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…åŒ…
        
        Args:
            env_path: è™šæ‹Ÿç¯å¢ƒè·¯å¾„
            packages: åŒ…åˆ—è¡¨
            
        Returns:
            bool: å®‰è£…æ˜¯å¦æˆåŠŸ
        """
        if sys.platform == 'win32':
            pip_path = env_path / 'Scripts' / 'pip.exe'
        else:
            pip_path = env_path / 'bin' / 'pip'
        
        logger.info(f"åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…åŒ…: {packages}")
        
        for package in packages:
            logger.info(f"å®‰è£…åŒ…: {package}")
            result = subprocess.run([
                str(pip_path), 'install', package
            ], capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"å®‰è£…åŒ… {package} å¤±è´¥: {result.stderr}")
                return False
        
        logger.info("æ‰€æœ‰åŒ…å®‰è£…å®Œæˆ")
        return True
    
    def download_model_in_venv(self, env_path: Path, model_name: str) -> bool:
        """
        åœ¨è™šæ‹Ÿç¯å¢ƒä¸­ä¸‹è½½æ¨¡å‹
        
        Args:
            env_path: è™šæ‹Ÿç¯å¢ƒè·¯å¾„
            model_name: æ¨¡å‹åç§°
            
        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        if sys.platform == 'win32':
            python_path = env_path / 'Scripts' / 'python.exe'
        else:
            python_path = env_path / 'bin' / 'python'
        
        # åˆ›å»ºä¸‹è½½è„šæœ¬
        download_script = self.build_dir / 'download_model.py'
        script_content = f'''
import os
import sys
from sentence_transformers import SentenceTransformer

# è®¾ç½®ç¼“å­˜ç›®å½•
cache_dir = "{self.build_dir / 'models_cache'}"
os.makedirs(cache_dir, exist_ok=True)
os.environ['HF_HOME'] = cache_dir
os.environ['TRANSFORMERS_CACHE'] = cache_dir

# ä¸‹è½½æ¨¡å‹
print(f"ä¸‹è½½æ¨¡å‹: {model_name}")
model = SentenceTransformer("{model_name}", cache_folder=cache_dir)

# æµ‹è¯•æ¨¡å‹
test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
embedding = model.encode([test_text])
print(f"æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œå‘é‡ç»´åº¦: {{embedding.shape}}")
print("æ¨¡å‹ä¸‹è½½å®Œæˆ")
'''
        
        with open(download_script, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        logger.info(f"åœ¨è™šæ‹Ÿç¯å¢ƒä¸­ä¸‹è½½æ¨¡å‹: {model_name}")
        result = subprocess.run([
            str(python_path), str(download_script)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            logger.error(f"ä¸‹è½½æ¨¡å‹å¤±è´¥: {result.stderr}")
            return False
        
        logger.info("æ¨¡å‹ä¸‹è½½å®Œæˆ")
        return True
    
    def build_ai_dependencies_package(self) -> bool:
        """
        æ„å»ºAIä¾èµ–åŒ…
        
        Returns:
            bool: æ„å»ºæ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹æ„å»ºAIä¾èµ–åŒ…...")
        
        try:
            # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
            env_path = self.create_virtual_environment('ai_deps')
            
            # å®‰è£…åŒ…
            config = self.package_configs['ai_dependencies']
            if not self.install_packages_to_venv(env_path, config['packages']):
                return False
            
            # åˆ›å»ºåŒ…ç›®å½•ç»“æ„
            package_dir = self.build_dir / 'ai_dependencies_package'
            if package_dir.exists():
                shutil.rmtree(package_dir)
            package_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶site-packages
            if sys.platform == 'win32':
                site_packages = env_path / 'Lib' / 'site-packages'
            else:
                site_packages = env_path / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'
            
            target_site_packages = package_dir / 'site-packages'
            shutil.copytree(site_packages, target_site_packages)
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = {
                'name': config['name'],
                'version': config['version'],
                'description': config['description'],
                'python_version': f"{sys.version_info.major}.{sys.version_info.minor}",
                'platform': sys.platform,
                'packages': config['packages'],
                'created_at': str(Path().cwd()),
                'build_info': {
                    'python_executable': sys.executable,
                    'build_dir': str(self.build_dir)
                }
            }
            
            with open(package_dir / 'metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # åˆ›å»ºZIPåŒ…
            zip_path = self.build_dir / f"ai_dependencies_v{config['version']}.zip"
            self.create_zip_package(package_dir, zip_path)
            
            # è®¡ç®—æ ¡éªŒå’Œ
            checksum = self.calculate_file_checksum(zip_path)
            logger.info(f"AIä¾èµ–åŒ…æ„å»ºå®Œæˆ: {zip_path}")
            logger.info(f"æ ¡éªŒå’Œ: {checksum}")
            
            return True
            
        except Exception as e:
            logger.error(f"æ„å»ºAIä¾èµ–åŒ…å¤±è´¥: {e}")
            return False
    
    def build_ai_models_package(self) -> bool:
        """
        æ„å»ºAIæ¨¡å‹åŒ…
        
        Returns:
            bool: æ„å»ºæ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹æ„å»ºAIæ¨¡å‹åŒ…...")
        
        try:
            # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶ä¸‹è½½æ¨¡å‹
            env_path = self.create_virtual_environment('ai_models')
            
            # å…ˆå®‰è£…å¿…è¦çš„åŒ…
            required_packages = ['sentence-transformers', 'torch', 'transformers']
            if not self.install_packages_to_venv(env_path, required_packages):
                return False
            
            # ä¸‹è½½æ¨¡å‹
            config = self.package_configs['ai_models']
            if not self.download_model_in_venv(env_path, config['model_name']):
                return False
            
            # åˆ›å»ºåŒ…ç›®å½•ç»“æ„
            package_dir = self.build_dir / 'ai_models_package'
            if package_dir.exists():
                shutil.rmtree(package_dir)
            package_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ¨¡å‹æ–‡ä»¶
            models_cache = self.build_dir / 'models_cache'
            if models_cache.exists():
                # å¤åˆ¶sentence transformeræ¨¡å‹
                st_source = models_cache / f"models--sentence-transformers--{config['model_name']}"
                st_target = package_dir / 'sentence-transformers' / config['model_name']
                st_target.mkdir(parents=True, exist_ok=True)
                
                if st_source.exists():
                    # æ‰¾åˆ°å®é™…çš„æ¨¡å‹æ–‡ä»¶
                    snapshots_dir = st_source / 'snapshots'
                    if snapshots_dir.exists():
                        for snapshot_dir in snapshots_dir.iterdir():
                            if snapshot_dir.is_dir():
                                shutil.copytree(snapshot_dir, st_target, dirs_exist_ok=True)
                                break
                
                # åˆ›å»ºfaissç´¢å¼•ç›®å½•ï¼ˆç©ºç›®å½•ï¼Œå®é™…ç´¢å¼•ä¼šåœ¨è¿è¡Œæ—¶åˆ›å»ºï¼‰
                faiss_dir = package_dir / 'similarity_index'
                faiss_dir.mkdir(parents=True, exist_ok=True)
                
                # åˆ›å»ºç©ºçš„faissç´¢å¼•æ–‡ä»¶
                (faiss_dir / 'faiss_index.bin').touch()
                (faiss_dir / 'metadata.json').write_text('{"created": false, "note": "å°†åœ¨è¿è¡Œæ—¶åˆ›å»º"}')
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = {
                'name': config['name'],
                'version': config['version'],
                'description': config['description'],
                'model_name': config['model_name'],
                'python_version': f"{sys.version_info.major}.{sys.version_info.minor}",
                'platform': sys.platform,
                'created_at': str(Path().cwd()),
                'build_info': {
                    'python_executable': sys.executable,
                    'build_dir': str(self.build_dir)
                }
            }
            
            with open(package_dir / 'metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # åˆ›å»ºZIPåŒ…
            zip_path = self.build_dir / f"ai_models_v{config['version']}.zip"
            self.create_zip_package(package_dir, zip_path)
            
            # è®¡ç®—æ ¡éªŒå’Œ
            checksum = self.calculate_file_checksum(zip_path)
            logger.info(f"AIæ¨¡å‹åŒ…æ„å»ºå®Œæˆ: {zip_path}")
            logger.info(f"æ ¡éªŒå’Œ: {checksum}")
            
            return True
            
        except Exception as e:
            logger.error(f"æ„å»ºAIæ¨¡å‹åŒ…å¤±è´¥: {e}")
            return False
    
    def create_zip_package(self, source_dir: Path, zip_path: Path) -> None:
        """
        åˆ›å»ºZIPåŒ…
        
        Args:
            source_dir: æºç›®å½•
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"åˆ›å»ºZIPåŒ…: {zip_path}")
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in source_dir.rglob('*'):
                if file_path.is_file():
                    arcname = file_path.relative_to(source_dir)
                    zipf.write(file_path, arcname)
        
        logger.info(f"ZIPåŒ…åˆ›å»ºå®Œæˆ: {zip_path}")
    
    def calculate_file_checksum(self, file_path: Path, algorithm: str = 'sha256') -> str:
        """
        è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            algorithm: æ ¡éªŒç®—æ³•
            
        Returns:
            str: æ ¡éªŒå’Œ
        """
        hash_func = hashlib.new(algorithm)
        
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_func.update(chunk)
        
        return f"{algorithm}:{hash_func.hexdigest()}"
    
    def build_all_packages(self) -> bool:
        """
        æ„å»ºæ‰€æœ‰åŒ…
        
        Returns:
            bool: æ„å»ºæ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹æ„å»ºæ‰€æœ‰é¢„ç¼–è¯‘åŒ…...")
        
        success = True
        
        # æ„å»ºAIä¾èµ–åŒ…
        if not self.build_ai_dependencies_package():
            success = False
        
        # æ„å»ºAIæ¨¡å‹åŒ…
        if not self.build_ai_models_package():
            success = False
        
        if success:
            logger.info("æ‰€æœ‰é¢„ç¼–è¯‘åŒ…æ„å»ºå®Œæˆ!")
            self.print_build_summary()
        else:
            logger.error("éƒ¨åˆ†é¢„ç¼–è¯‘åŒ…æ„å»ºå¤±è´¥!")
        
        return success
    
    def print_build_summary(self):
        """æ‰“å°æ„å»ºæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“¦ é¢„ç¼–è¯‘åŒ…æ„å»ºæ‘˜è¦")
        print("="*60)
        
        for package_name in ['ai_dependencies', 'ai_models']:
            config = self.package_configs[package_name]
            zip_path = self.build_dir / f"{package_name}_v{config['version']}.zip"
            
            if zip_path.exists():
                size_mb = zip_path.stat().st_size / (1024 * 1024)
                checksum = self.calculate_file_checksum(zip_path)
                print(f"\nğŸ“¦ {package_name} v{config['version']}")
                print(f"   æ–‡ä»¶: {zip_path.name}")
                print(f"   å¤§å°: {size_mb:.1f} MB")
                print(f"   æ ¡éªŒå’Œ: {checksum}")
            else:
                print(f"\nâŒ {package_name} - æ„å»ºå¤±è´¥")
        
        print(f"\nğŸ“ æ„å»ºç›®å½•: {self.build_dir}")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. å°†ç”Ÿæˆçš„ZIPæ–‡ä»¶ä¸Šä¼ åˆ°CDN")
        print("   2. æ›´æ–° precompiled_package_manager.py ä¸­çš„ä¸‹è½½åœ°å€å’Œæ ¡éªŒå’Œ")
        print("   3. æµ‹è¯•é¢„ç¼–è¯‘åŒ…ä¸‹è½½å’Œå®‰è£…")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ é¢„ç¼–è¯‘åŒ…æ„å»ºå·¥å…·")
    print("="*50)
    
    builder = PrecompiledPackageBuilder()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
    if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):
        print("âœ… æ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œå»ºè®®åœ¨è™šæ‹Ÿç¯å¢ƒä¸­æ„å»º")
        response = input("æ˜¯å¦ç»§ç»­æ„å»º? (y/N): ")
        if response.lower() != 'y':
            print("æ„å»ºå·²å–æ¶ˆ")
            return
    
    # æ„å»ºæ‰€æœ‰åŒ…
    success = builder.build_all_packages()
    
    if success:
        print("\nğŸ‰ é¢„ç¼–è¯‘åŒ…æ„å»ºå®Œæˆ!")
    else:
        print("\nâŒ é¢„ç¼–è¯‘åŒ…æ„å»ºå¤±è´¥!")
        sys.exit(1)


if __name__ == '__main__':
    main()
